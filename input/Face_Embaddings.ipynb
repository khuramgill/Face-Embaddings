{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrBOzE0BEOXSWJLhsoUgyL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khuramgill/Face-Embaddings/blob/main/Face_Embaddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SZ-QXrt1IRwc",
        "outputId": "9ab03bae-52fd-405a-f40a-ac9da13359fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepface\n",
            "  Downloading deepface-0.0.93-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.2.2)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (5.2.0)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.66.6)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (10.4.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.10.0.84)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.17.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (3.4.1)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.2.5)\n",
            "Collecting flask-cors>=4.0.1 (from deepface)\n",
            "  Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting mtcnn>=0.1.0 (from deepface)\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting retina-face>=0.0.1 (from deepface)\n",
            "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting fire>=0.4.0 (from deepface)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gunicorn>=20.1.0 (from deepface)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (2.5.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (8.1.7)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (3.16.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gunicorn>=20.1.0->deepface) (24.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (0.13.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (0.4.1)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from mtcnn>=0.1.0->deepface) (1.4.2)\n",
            "Collecting lz4>=4.3.3 (from mtcnn>=0.1.0->deepface)\n",
            "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (2024.8.30)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.44.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=1.1.2->deepface) (3.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=1.9.0->deepface) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=1.9.0->deepface) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=2.2.0->deepface) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=2.2.0->deepface) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n",
            "Downloading deepface-0.0.93-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.6/108.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\n",
            "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
            "Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=fc186654df5b13b22ba2f3b0145ee13d481fded8bff7cb2ce1675a8fdaff26ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "Successfully built fire\n",
            "Installing collected packages: lz4, gunicorn, fire, mtcnn, flask-cors, retina-face, deepface\n",
            "Successfully installed deepface-0.0.93 fire-0.7.0 flask-cors-5.0.0 gunicorn-23.0.0 lz4-4.3.3 mtcnn-1.0.0 retina-face-0.0.17\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.10/dist-packages (5.0.1)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.8.30)\n",
            "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.1.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install deepface\n",
        "!pip install pinecone-client\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "Ocg2GQFaI74g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from deepface import DeepFace\n",
        "from typing import List, Dict, Tuple\n",
        "import pinecone\n",
        "from datetime import datetime\n",
        "import uuid\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "luzAxjOeJ1JH",
        "outputId": "9faec925-f686-478b-c705-89942df75cd4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24-11-12 11:53:31 - Directory /root/.deepface has been created\n",
            "24-11-12 11:53:31 - Directory /root/.deepface/weights has been created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FaceEmbeddingSystem**"
      ],
      "metadata": {
        "id": "y_oeUgJ4OY1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceEmbeddingSystem:\n",
        "    def __init__(\n",
        "        self,\n",
        "        pinecone_api_key: str,\n",
        "        pinecone_environment: str,\n",
        "        index_name: str,\n",
        "        model_name: str = \"VGG-Face\",  # Options: \"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\"\n",
        "        dimension: int = 2622  # Dimension varies by model: VGG-Face=2622, Facenet=128, Facenet512=512\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize the face embedding system\n",
        "\n",
        "        Args:\n",
        "            pinecone_api_key: Your Pinecone API key\n",
        "            pinecone_environment: Pinecone environment\n",
        "            index_name: Name for Pinecone index\n",
        "            model_name: Name of the face recognition model to use\n",
        "            dimension: Embedding dimension (depends on model)\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "\n",
        "        # Initialize Pinecone\n",
        "        pinecone.init(api_key=pinecone_api_key, environment=pinecone_environment)\n",
        "\n",
        "        # Create index if it doesn't exist\n",
        "        if index_name not in pinecone.list_indexes():\n",
        "            pinecone.create_index(\n",
        "                name=index_name,\n",
        "                dimension=dimension,\n",
        "                metric=\"cosine\"\n",
        "            )\n",
        "\n",
        "        self.index = pinecone.Index(index_name)\n",
        "\n",
        "    def visualize_faces(self, image_path: str):\n",
        "        \"\"\"\n",
        "        Detect and visualize faces in an image\n",
        "        \"\"\"\n",
        "        # Read image\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Detect faces\n",
        "        faces = DeepFace.extract_faces(\n",
        "            img_path=image_path,\n",
        "            target_size=(224, 224),\n",
        "            detector_backend='opencv'\n",
        "        )\n",
        "\n",
        "        # Draw rectangles around faces\n",
        "        for face in faces:\n",
        "            facial_area = face['facial_area']\n",
        "            x = facial_area['x']\n",
        "            y = facial_area['y']\n",
        "            w = facial_area['w']\n",
        "            h = facial_area['h']\n",
        "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "        # Display image\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        return len(faces)\n",
        "\n",
        "    def process_image(self, image_path: str) -> Tuple[List[np.ndarray], Dict]:\n",
        "        \"\"\"\n",
        "        Process image and extract face embeddings\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Extract faces and embeddings\n",
        "            embeddings = DeepFace.represent(\n",
        "                img_path=image_path,\n",
        "                model_name=self.model_name,\n",
        "                detector_backend='opencv'\n",
        "            )\n",
        "\n",
        "            # If single embedding is returned, convert to list\n",
        "            if isinstance(embeddings, dict):\n",
        "                embeddings = [embeddings]\n",
        "\n",
        "            # Extract embedding vectors\n",
        "            embedding_vectors = [emb['embedding'] for emb in embeddings]\n",
        "\n",
        "            # Create metadata\n",
        "            metadata = {\n",
        "                \"original_image\": image_path,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"num_faces\": len(embedding_vectors),\n",
        "                \"model_name\": self.model_name\n",
        "            }\n",
        "\n",
        "            return embedding_vectors, metadata\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {image_path}: {str(e)}\")\n",
        "            return [], {}\n",
        "\n",
        "    def store_embeddings(\n",
        "        self,\n",
        "        embeddings: List[np.ndarray],\n",
        "        metadata: Dict,\n",
        "        event_id: str = None\n",
        "    ) -> List[str]:\n",
        "        \"\"\"\n",
        "        Store face embeddings in Pinecone\n",
        "        \"\"\"\n",
        "        vectors = []\n",
        "        ids = []\n",
        "\n",
        "        # Process each face embedding\n",
        "        for idx, embedding in enumerate(embeddings):\n",
        "            # Generate unique ID\n",
        "            face_id = str(uuid.uuid4())\n",
        "            ids.append(face_id)\n",
        "\n",
        "            # Prepare metadata\n",
        "            face_metadata = {\n",
        "                **metadata,\n",
        "                \"face_index\": idx,\n",
        "                \"event_id\": event_id\n",
        "            }\n",
        "\n",
        "            # Convert embedding to list if necessary\n",
        "            embedding_list = embedding.tolist() if isinstance(embedding, np.ndarray) else embedding\n",
        "\n",
        "            # Prepare vector\n",
        "            vectors.append({\n",
        "                \"id\": face_id,\n",
        "                \"values\": embedding_list,\n",
        "                \"metadata\": face_metadata\n",
        "            })\n",
        "\n",
        "        # Upsert vectors in batches\n",
        "        batch_size = 100\n",
        "        for i in range(0, len(vectors), batch_size):\n",
        "            batch = vectors[i:i + batch_size]\n",
        "            self.index.upsert(vectors=batch)\n",
        "\n",
        "        return ids"
      ],
      "metadata": {
        "id": "rFjja9hhI6u4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**upload_and_process_images**"
      ],
      "metadata": {
        "id": "6rxSQcPRJBaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_and_process_images():\n",
        "    \"\"\"Upload images through Colab interface\"\"\"\n",
        "    print(\"Please upload your images:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Create directory if it doesn't exist\n",
        "    if not os.path.exists('uploaded_images'):\n",
        "        os.makedirs('uploaded_images')\n",
        "\n",
        "    # Save uploaded files\n",
        "    for filename, content in uploaded.items():\n",
        "        with open(os.path.join('uploaded_images', filename), 'wb') as f:\n",
        "            f.write(content)\n",
        "\n",
        "    return list(uploaded.keys())"
      ],
      "metadata": {
        "id": "8hLgUWTdJHMX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main**"
      ],
      "metadata": {
        "id": "RIGDvRCOOmsq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Clean/Working Code**"
      ],
      "metadata": {
        "id": "876MlFChvvHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install necessary libraries\n",
        "!pip install keras_facenet opencv-python-headless\n",
        "!pip install opencv-python scikit-learn keras_facenet matplotlib\n",
        "!pip install tk  # for file dialog\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsZX4swVqDx1",
        "outputId": "e8f44d3e-59ce-4e08-c338-3614a165e6d9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras_facenet in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.10/dist-packages (from keras_facenet) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from mtcnn->keras_facenet) (1.4.2)\n",
            "Requirement already satisfied: lz4>=4.3.3 in /usr/local/lib/python3.10/dist-packages (from mtcnn->keras_facenet) (4.3.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: keras_facenet in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.10/dist-packages (from keras_facenet) (1.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: lz4>=4.3.3 in /usr/local/lib/python3.10/dist-packages (from mtcnn->keras_facenet) (4.3.3)\n",
            "Collecting tk\n",
            "  Downloading tk-0.1.0-py3-none-any.whl.metadata (693 bytes)\n",
            "Downloading tk-0.1.0-py3-none-any.whl (3.9 kB)\n",
            "Installing collected packages: tk\n",
            "Successfully installed tk-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test code\n"
      ],
      "metadata": {
        "id": "MzqzfbdKv6hZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from keras_facenet import FaceNet\n",
        "import matplotlib.pyplot as plt\n",
        "from tkinter import Tk\n",
        "from tkinter.filedialog import askopenfilename\n",
        "\n",
        "# Initialize FaceNet model\n",
        "embedder = FaceNet()\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_and_preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Image not found at path: {image_path}\")\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (160, 160))\n",
        "    return img\n",
        "\n",
        "# Function to let the user select an image file\n",
        "def select_image():\n",
        "    # Hide the Tkinter root window\n",
        "    Tk().withdraw()\n",
        "    # Open a file dialog and return the selected file path\n",
        "    file_path = askopenfilename(title=\"Select Image\", filetypes=[(\"Image Files\", \"*.jpg;*.jpeg;*.png\")])\n",
        "    if not file_path:\n",
        "        print(\"No file selected\")\n",
        "    return file_path\n",
        "\n",
        "# Select an image interactively\n",
        "search_img_path = select_image()  # Open file dialog to select image\n",
        "\n",
        "if search_img_path:  # Proceed only if a file is selected\n",
        "    try:\n",
        "        # Load and preprocess the selected image\n",
        "        search_img = load_and_preprocess_image(search_img_path)\n",
        "        search_embedding = np.array(embedder.embeddings([search_img]), dtype=np.float64)[0]\n",
        "\n",
        "        # Step 2: Extract features using FaceNet\n",
        "        # List of image file paths (Ensure paths are correct)\n",
        "        images = [\n",
        "            '/content/sample_data/19.jpg',\n",
        "            '/content/sample_data/33.jpg'  # Add more paths as needed\n",
        "        ]\n",
        "\n",
        "        # Load and preprocess images\n",
        "        preprocessed_images = [load_and_preprocess_image(img_path) for img_path in images]\n",
        "\n",
        "        # Step 3: Extract features for all images\n",
        "        features = np.array(embedder.embeddings(preprocessed_images), dtype=np.float64)\n",
        "\n",
        "        # Perform K-means clustering\n",
        "        num_clusters = min(5, len(features))  # Set to min(5, number of images) to avoid cluster errors\n",
        "        kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(features)\n",
        "\n",
        "        # Step 4: To search for a specific face\n",
        "        # Predict the cluster for the search image\n",
        "        search_cluster = kmeans.predict([search_embedding])[0]\n",
        "\n",
        "        # Retrieve all images in the same cluster\n",
        "        cluster_images = [images[i] for i in range(len(images)) if kmeans.labels_[i] == search_cluster]\n",
        "\n",
        "        # Function to display images in a cluster\n",
        "        def display_images(image_paths, title):\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            for i, img_path in enumerate(image_paths):\n",
        "                plt.subplot(1, len(image_paths), i + 1)\n",
        "                img = load_and_preprocess_image(img_path)\n",
        "                plt.imshow(img)\n",
        "                plt.axis('off')\n",
        "            plt.suptitle(title)\n",
        "            plt.show()\n",
        "\n",
        "        # Display the search result cluster\n",
        "        display_images(cluster_images, f'Cluster for Search Image: {search_img_path}')\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "ScpQSi0mv87a",
        "outputId": "2d0a434c-3e10-4162-93a3-dd4babdc15c8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TclError",
          "evalue": "no display name and no $DISPLAY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-d5f3c27c3e7a>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Select an image interactively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0msearch_img_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Open file dialog to select image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msearch_img_path\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Proceed only if a file is selected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-d5f3c27c3e7a>\u001b[0m in \u001b[0;36mselect_image\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Hide the Tkinter root window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Open a file dialog and return the selected file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maskopenfilename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Select Image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiletypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image Files\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"*.jpg;*.jpeg;*.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2297\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2298\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2299\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2301\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from keras_facenet import FaceNet\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize FaceNet model\n",
        "embedder = FaceNet()\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_and_preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Image not found at path: {image_path}\")\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (160, 160))\n",
        "    return img\n",
        "\n",
        "# List of image file paths (Ensure paths are correct)\n",
        "images = [\n",
        "    '/content/sample_data/19.jpg',\n",
        "    '/content/sample_data/33.jpg'    # Add more paths as needed\n",
        "]\n",
        "\n",
        "# Load and preprocess images\n",
        "preprocessed_images = [load_and_preprocess_image(img_path) for img_path in images]\n",
        "\n",
        "# Step 2: Extract features using FaceNet\n",
        "# Convert features to float64 for compatibility with KMeans\n",
        "features = np.array(embedder.embeddings(preprocessed_images), dtype=np.float64)\n",
        "\n",
        "# Step 3: Perform K-means clustering\n",
        "num_clusters = min(5, len(features))  # Set to min(5, number of images) to avoid cluster errors\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(features)\n",
        "\n",
        "# Function to display images in a cluster\n",
        "def display_images(image_paths, title):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i, img_path in enumerate(image_paths):\n",
        "        plt.subplot(1, len(image_paths), i + 1)\n",
        "        img = load_and_preprocess_image(img_path)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Step 4: To search for a specific face\n",
        "search_img_path = '/content/sample_data/4.jpg'  # Update with the path of the search image\n",
        "try:\n",
        "    search_img = load_and_preprocess_image(search_img_path)\n",
        "    search_embedding = np.array(embedder.embeddings([search_img]), dtype=np.float64)[0]\n",
        "\n",
        "    # Predict the cluster for the search image\n",
        "    search_cluster = kmeans.predict([search_embedding])[0]\n",
        "\n",
        "    # Retrieve all images in the same cluster\n",
        "    cluster_images = [images[i] for i in range(len(images)) if kmeans.labels_[i] == search_cluster]\n",
        "\n",
        "    # Display the search result cluster\n",
        "    display_images(cluster_images, f'Cluster for Search Image: {search_img_path}')\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(e)\n"
      ],
      "metadata": {
        "id": "fWHnWBP7o0LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clean Code Above**"
      ],
      "metadata": {
        "id": "utuV4WdWvnCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Get Pinecone credentials\n",
        "    PINECONE_API_KEY = input(\"Enter your Pinecone API key: \")\n",
        "    PINECONE_ENV = input(\"Enter your Pinecone environment: \")\n",
        "    INDEX_NAME = \"face-embeddings\"\n",
        "\n",
        "    # Choose face recognition model\n",
        "    MODEL_NAME = \"VGG-Face\"  # Default model\n",
        "\n",
        "    # Initialize system\n",
        "    system = FaceEmbeddingSystem(\n",
        "        pinecone_api_key=PINECONE_API_KEY,\n",
        "        pinecone_environment=PINECONE_ENV,\n",
        "        index_name=INDEX_NAME,\n",
        "        model_name=MODEL_NAME\n",
        "    )\n",
        "\n",
        "    # Upload and process images\n",
        "    print(\"\\nUpload your images:\")\n",
        "    uploaded_files = upload_and_process_images()\n",
        "\n",
        "    # Get event ID (optional)\n",
        "    event_id = input(\"\\nEnter an event ID (or press Enter to skip): \")\n",
        "    if not event_id:\n",
        "        event_id = None\n",
        "\n",
        "    # Process each image\n",
        "    results = {}\n",
        "    for filename in uploaded_files:\n",
        "        image_path = os.path.join('uploaded_images', filename)\n",
        "        try:\n",
        "            print(f\"\\nProcessing {filename}:\")\n",
        "\n",
        "            # Visualize faces\n",
        "            num_faces = system.visualize_faces(image_path)\n",
        "            print(f\"Found {num_faces} faces\")\n",
        "\n",
        "            # Get embeddings and store them\n",
        "            embeddings, metadata = system.process_image(image_path)\n",
        "            if embeddings:\n",
        "                face_ids = system.store_embeddings(embeddings, metadata, event_id)\n",
        "                results[filename] = face_ids\n",
        "                print(f\"Successfully stored {len(face_ids)} face embeddings\")\n",
        "            else:\n",
        "                results[filename] = []\n",
        "                print(\"No faces processed in this image\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {str(e)}\")\n",
        "            results[filename] = []\n",
        "\n",
        "    # Print final results\n",
        "    print(\"\\nProcessing Summary:\")\n",
        "    for filename, face_ids in results.items():\n",
        "        print(f\"\\nImage: {filename}\")\n",
        "        print(f\"Face IDs: {face_ids}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "CysdOqSgOpHi",
        "outputId": "be94e538-ef1b-4a23-eaf5-a71dac5feb2b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Pinecone API key: pcsk_2agnRW_PJGcuYNduPh4LXPttu1bnT31UninNBGbyZqKDUiCDAxdY7asgDJkLHmR3KCDJzP\n",
            "Enter your Pinecone environment: us-west-2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "FaceEmbeddingSystem.__init__() got an unexpected keyword argument 'pinecone_api_key'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-64854becf447>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-64854becf447>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Initialize system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     system = FaceEmbeddingSystem(\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mpinecone_api_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPINECONE_API_KEY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpinecone_environment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPINECONE_ENV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: FaceEmbeddingSystem.__init__() got an unexpected keyword argument 'pinecone_api_key'"
          ]
        }
      ]
    }
  ]
}